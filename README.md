# Auditory Experience Language

This is an example page for the Auditory Experience Language; a proposed set of universal sounds that signal
waiting, completion, and error conditions for devices interacting with humans using auditory signals as a complement
to the visual input. By unifying these auditory feedback signals, we try to create a language that is intuitively
understood across different domains.

[The example, AUXL.html](https://mgefvert.github.io/auxl/AUXL.html) is simply a couple of buttons that give auditory feedback using the Web Audio API in web browsers.

- The language consist mainly of sequences of high, middle, and low signals. Primary focus is given to
  high and low signals since it's possible devices may not be able to emit middle tone signals.
- The speed of each tone is not mandatory but encouraged.
